# Default values for tfjob.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

useHostNetwork: false
useHostPID: false
useHostIPC: false
gpuCount: 0 # user define
privileged: false

chief: 0
# Possible value: Chief/Master
chiefName: Chief
# chiefPort: 2221
chiefAnnotations:
  k8s.v1.cni.cncf.io/networks: '[{ "name": "sriov-conf" }]'
# chiefAnnotations:

workers: 1
workerImage: kubeflow/tf-dist-mnist-test:1.0
# workerCpu: 1
# workerMemory: 1 Gi
# workPort: 2222
workerAnnotations:
  k8s.v1.cni.cncf.io/networks: '[{ "name": "sriov-conf" }]'

ps: 0
psImage: kubeflow/tf-dist-mnist-test:1.0
# psCpu: 1
# psMemory: 1 Gi
# psPort: 2223
annotations: {}

psAnnotations:
  k8s.v1.cni.cncf.io/networks: '[{ "name": "sriov-conf" }]'

evaluator: 0
evaluatorImage: kubeflow/tf-dist-mnist-test:1.0
evaluatorAnnotations:
  k8s.v1.cni.cncf.io/networks: '[{ "name": "sriov-conf" }]'

# rsync image
rsyncImage: registry.cn-zhangjiakou.aliyuncs.com/tensorflow-samples/rsync
# git sync image
gitImage: registry.cn-zhangjiakou.aliyuncs.com/tensorflow-samples/git-sync:v3.1.1

imagePullPolicy: Always

useTensorboard: false
tensorboardImage: registry.cn-zhangjiakou.aliyuncs.com/tensorflow-samples/tensorflow:1.5.0-devel
tensorboardImagePullpolicy: Always
tensorboardServiceType: NodePort
tensorboardResources: {}
# tensorboardResources:
#   limits:
#     cpu: 500m
#     memory: 500Mi
#   requests:
#     cpu: 500m
#     memory: 500Mi

trainingLogdir: /output/training_logs

# disable by default 
binpack: true

# enable gang scheduler
enableGangScheduler: false
schedulerName: kube-batchd

# enable RDMA support
enableRDMA: false
RDMAType: vhca




ingress: false

# hostLogPath: /training_logs/112345_logs

# nvidiaPath: /usr/local/nvidia-docker/nvidia_driver/384.81

# enable PodSecurityContext
# In the future, this flag should be protected separately, in case of arena admin and users are not the same people
enablePodSecurityContext: false


# enable priorityClassName
priorityClassName: ""

tolerations:
- key: nvidia.com/gpu
  operator: Exists
  effect: NoSchedule
nodeAffinity:
  requiredDuringSchedulingIgnoredDuringExecution:
    nodeSelectorTerms:
    - matchExpressions:
      - key: nvidia.com/gpu
        operator: In
        values:
        - ""
